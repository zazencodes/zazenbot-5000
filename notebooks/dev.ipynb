{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview import rag\n",
    "import vertexai\n",
    "import os\n",
    "from vertexai.preview.rag.utils.resources import ChunkingConfig, TransformationConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"../.credentials/.zazencodes-2b1cb01be0fa.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID=\"zazencodes\"\n",
    "LOCATION=\"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListRagCorporaPager<rag_corpora {\n",
       "  name: \"projects/zazencodes/locations/us-central1/ragCorpora/1152921504606846976\"\n",
       "  display_name: \"zazenbot-5000-video-transcripts\"\n",
       "  description: \"Transcripts and other metadata for ZazenCodes YouTube videos\"\n",
       "  create_time {\n",
       "    seconds: 1741265740\n",
       "    nanos: 490300000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1741265740\n",
       "    nanos: 490300000\n",
       "  }\n",
       "  rag_embedding_model_config {\n",
       "    vertex_prediction_endpoint {\n",
       "      endpoint: \"projects/890511813715/locations/us-central1/publishers/google/models/text-embedding-005\"\n",
       "    }\n",
       "  }\n",
       "  rag_vector_db_config {\n",
       "    rag_managed_db {\n",
       "    }\n",
       "    rag_embedding_model_config {\n",
       "      vertex_prediction_endpoint {\n",
       "        endpoint: \"projects/890511813715/locations/us-central1/publishers/google/models/text-embedding-005\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  corpus_status {\n",
       "    state: ACTIVE\n",
       "  }\n",
       "  vector_db_config {\n",
       "    rag_managed_db {\n",
       "    }\n",
       "    rag_embedding_model_config {\n",
       "      vertex_prediction_endpoint {\n",
       "        endpoint: \"projects/890511813715/locations/us-central1/publishers/google/models/text-embedding-005\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  rag_files_count: 11\n",
       "}\n",
       ">"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.list_corpora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully deleted the RagCorpus.\n"
     ]
    }
   ],
   "source": [
    "rag.delete_corpus(\"projects/zazencodes/locations/us-central1/ragCorpora/1152921504606846976\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListRagCorporaPager<>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.list_corpora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created corpus: RagCorpus(name='projects/890511813715/locations/us-central1/ragCorpora/5685794529555251200', display_name='zazenbot-5000-video-transcripts', description='Transcripts and other metadata for ZazenCodes YouTube videos', embedding_model_config=EmbeddingModelConfig(publisher_model='projects/890511813715/locations/us-central1/publishers/google/models/text-embedding-005', endpoint=None, model=None, model_version_id=None), vector_db=RagManagedDb(), vertex_ai_search_config=None, backend_config=RagVectorDbConfig(vector_db=RagManagedDb(), rag_embedding_model_config=None))\n"
     ]
    }
   ],
   "source": [
    "corpus = rag.create_corpus(\n",
    "    display_name=\"zazenbot-5000-video-transcripts\",\n",
    "    description=\"Transcripts and other metadata for ZazenCodes YouTube videos\",\n",
    ")\n",
    "print(\"Created corpus:\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RagCorpus(name='projects/890511813715/locations/us-central1/ragCorpora/5685794529555251200', display_name='zazenbot-5000-video-transcripts', description='Transcripts and other metadata for ZazenCodes YouTube videos', embedding_model_config=EmbeddingModelConfig(publisher_model='projects/890511813715/locations/us-central1/publishers/google/models/text-embedding-005', endpoint=None, model=None, model_version_id=None), vector_db=RagManagedDb(), vertex_ai_search_config=None, backend_config=RagVectorDbConfig(vector_db=RagManagedDb(), rag_embedding_model_config=RagEmbeddingModelConfig(vertex_prediction_endpoint=VertexPredictionEndpoint(endpoint=None, publisher_model='projects/890511813715/locations/us-central1/publishers/google/models/text-embedding-005', model=None, model_version_id=None))))\n"
     ]
    }
   ],
   "source": [
    "corpus_name = \"projects/890511813715/locations/us-central1/ragCorpora/5685794529555251200\"\n",
    "corpus = rag.get_corpus(corpus_name)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To delete it run this:\n",
    "# rag.delete_corpus(name=corpus_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'vertexai.preview.rag' from '/Users/alex/pro/zazenbot-5000/venv/lib/python3.12/site-packages/vertexai/preview/rag/__init__.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "rag.import_files(\n",
      "    corpus_name: str,\n",
      "    paths: Optional[Sequence[str]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    source: Union[vertexai.preview.rag.utils.resources.SlackChannelsSource, vertexai.preview.rag.utils.resources.JiraSource, vertexai.preview.rag.utils.resources.SharePointSources, NoneType] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    chunk_size: int = \u001b[32m1024\u001b[39m,\n",
      "    chunk_overlap: int = \u001b[32m200\u001b[39m,\n",
      "    transformation_config: Optional[vertexai.preview.rag.utils.resources.TransformationConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    timeout: int = \u001b[32m600\u001b[39m,\n",
      "    max_embedding_requests_per_min: int = \u001b[32m1000\u001b[39m,\n",
      "    use_advanced_pdf_parsing: Optional[bool] = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    partial_failures_sink: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    layout_parser: Optional[vertexai.preview.rag.utils.resources.LayoutParserConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    llm_parser: Optional[vertexai.preview.rag.utils.resources.LlmParserConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      ") -> google.cloud.aiplatform_v1beta1.types.vertex_rag_data_service.ImportRagFilesResponse\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Import files to an existing RagCorpus, wait until completion.\n",
      "\n",
      "Example usage:\n",
      "\n",
      "```\n",
      "import vertexai\n",
      "from vertexai.preview import rag\n",
      "from google.protobuf import timestamp_pb2\n",
      "\n",
      "vertexai.init(project=\"my-project\")\n",
      "# Google Drive example\n",
      "paths = [\n",
      "    \"https://drive.google.com/file/d/123\",\n",
      "    \"https://drive.google.com/drive/folders/456\"\n",
      "]\n",
      "# Google Cloud Storage example\n",
      "paths = [\"gs://my_bucket/my_files_dir\", ...]\n",
      "\n",
      "transformation_config = TransformationConfig(\n",
      "    chunking_config=ChunkingConfig(\n",
      "        chunk_size=1024,\n",
      "        chunk_overlap=200,\n",
      "    ),\n",
      ")\n",
      "\n",
      "response = rag.import_files(\n",
      "    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n",
      "    paths=paths,\n",
      "    transformation_config=transformation_config,\n",
      ")\n",
      "\n",
      "# Slack example\n",
      "start_time = timestamp_pb2.Timestamp()\n",
      "start_time.FromJsonString('2020-12-31T21:33:44Z')\n",
      "end_time = timestamp_pb2.Timestamp()\n",
      "end_time.GetCurrentTime()\n",
      "source = rag.SlackChannelsSource(\n",
      "    channels = [\n",
      "        SlackChannel(\"channel1\", \"api_key1\"),\n",
      "        SlackChannel(\"channel2\", \"api_key2\", start_time, end_time)\n",
      "    ],\n",
      ")\n",
      "# Jira Example\n",
      "jira_query = rag.JiraQuery(\n",
      "    email=\"xxx@yyy.com\",\n",
      "    jira_projects=[\"project1\", \"project2\"],\n",
      "    custom_queries=[\"query1\", \"query2\"],\n",
      "    api_key=\"api_key\",\n",
      "    server_uri=\"server.atlassian.net\"\n",
      ")\n",
      "source = rag.JiraSource(\n",
      "    queries=[jira_query],\n",
      ")\n",
      "\n",
      "response = rag.import_files(\n",
      "    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n",
      "    source=source,\n",
      "    transformation_config=transformation_config,\n",
      ")\n",
      "\n",
      "# SharePoint Example.\n",
      "sharepoint_query = rag.SharePointSource(\n",
      "    sharepoint_folder_path=\"https://my-sharepoint-site.com/my-folder\",\n",
      "    sharepoint_site_name=\"my-sharepoint-site.com\",\n",
      "    client_id=\"my-client-id\",\n",
      "    client_secret=\"my-client-secret\",\n",
      "    tenant_id=\"my-tenant-id\",\n",
      "    drive_id=\"my-drive-id\",\n",
      ")\n",
      "source = rag.SharePointSources(\n",
      "    share_point_sources=[sharepoint_query],\n",
      ")\n",
      "\n",
      "# Return the number of imported RagFiles after completion.\n",
      "print(response.imported_rag_files_count)\n",
      "\n",
      "```\n",
      "Args:\n",
      "    corpus_name: The name of the RagCorpus resource into which to import files.\n",
      "        Format: ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n",
      "        or ``{rag_corpus}``.\n",
      "    paths: A list of uris. Eligible uris will be Google Cloud Storage\n",
      "        directory (\"gs://my-bucket/my_dir\") or a Google Drive url for file\n",
      "        (https://drive.google.com/file/... or folder\n",
      "        \"https://drive.google.com/corp/drive/folders/...\").\n",
      "    source: The source of the Slack or Jira import.\n",
      "        Must be either a SlackChannelsSource or JiraSource.\n",
      "    chunk_size: The size of the chunks. This field is deprecated. Please use\n",
      "        transformation_config instead.\n",
      "    chunk_overlap: The overlap between chunks. This field is deprecated. Please use\n",
      "        transformation_config instead.\n",
      "    transformation_config: The config for transforming the imported\n",
      "        RagFiles.\n",
      "    max_embedding_requests_per_min:\n",
      "        Optional. The max number of queries per\n",
      "        minute that this job is allowed to make to the\n",
      "        embedding model specified on the corpus. This\n",
      "        value is specific to this job and not shared\n",
      "        across other import jobs. Consult the Quotas\n",
      "        page on the project to set an appropriate value\n",
      "        here. If unspecified, a default value of 1,000\n",
      "        QPM would be used.\n",
      "    timeout: Default is 600 seconds.\n",
      "    use_advanced_pdf_parsing: Whether to use advanced PDF\n",
      "        parsing on uploaded files. This field is deprecated.\n",
      "    partial_failures_sink: Either a GCS path to store partial failures or a\n",
      "        BigQuery table to store partial failures. The format is\n",
      "        \"gs://my-bucket/my/object.ndjson\" for GCS or\n",
      "        \"bq://my-project.my-dataset.my-table\" for BigQuery. An existing GCS\n",
      "        object cannot be used. However, the BigQuery table may or may not\n",
      "        exist - if it does not exist, it will be created. If it does exist,\n",
      "        the schema will be checked and the partial failures will be appended\n",
      "        to the table.\n",
      "    layout_parser: Configuration for the Document AI Layout Parser Processor\n",
      "        to use for document parsing. Optional.\n",
      "        If not None, the other parser configs must be None.\n",
      "    llm_parser: Configuration for the LLM Parser to use for document parsing.\n",
      "        Optional.\n",
      "        If not None, the other parser configs must be None.\n",
      "Returns:\n",
      "    ImportRagFilesResponse.\n",
      "\u001b[31mFile:\u001b[39m      ~/pro/zazenbot-5000/venv/lib/python3.12/site-packages/vertexai/preview/rag/rag_data.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "rag.import_files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListRagFilesPager<>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.list_files(corpus_name=corpus_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_config = TransformationConfig(\n",
    "    chunking_config=ChunkingConfig(\n",
    "        chunk_size=512,\n",
    "        chunk_overlap=100,\n",
    "    ),\n",
    ")\n",
    "\n",
    "response = rag.import_files(\n",
    "    corpus_name=corpus_name,\n",
    "    paths=[f\"gs://zazenbot-5000/yt-rag/transcript-markers\"],\n",
    "    transformation_config=transformation_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025_01_08_finally_figured_out_what_to_do.txt\n",
      "projects/890511813715/locations/us-central1/ragCorpora/5685794529555251200/ragFiles/5385707230544743269\n",
      "2025_01_21_how_i_use_ai_for_my_data_engineering_work.txt\n",
      "projects/890511813715/locations/us-central1/ragCorpora/5685794529555251200/ragFiles/5385707236411540478\n",
      "2025_01_15_the_awesome_power_of_an_llm_in_your_terminal.txt\n",
      "projects/890511813715/locations/us-central1/ragCorpora/5685794529555251200/ragFiles/5385707236417156356\n",
      "2025_01_24_12_neovim_ai_data_engineering_use_cases.txt\n",
      "projects/890511813715/locations/us-central1/ragCorpora/5685794529555251200/ragFiles/5385707237529713032\n",
      "2025_02_05_100_ai_job_postings_later_heres_whats_actually_in_demand.txt\n",
      "projects/890511813715/locations/us-central1/ragCorpora/5685794529555251200/ragFiles/5385707320646708101\n",
      "2025_01_29_data_jobs_in_2025.txt\n",
      "projects/890511813715/locations/us-central1/ragCorpora/5685794529555251200/ragFiles/5385707323063833009\n",
      "2025_02_19_5_level_gear_guide_for_modern_tech_workers.txt\n",
      "projects/890511813715/locations/us-central1/ragCorpora/5685794529555251200/ragFiles/5385707324731587909\n",
      "2025_02_12_how_to_setup_and_run_deepseek_r1_locally_using_ollama.txt\n",
      "projects/890511813715/locations/us-central1/ragCorpora/5685794529555251200/ragFiles/5385707325078734274\n",
      "2025_02_26_ai_startup_tier_list_whats_worth_building_in_2025.txt\n",
      "projects/890511813715/locations/us-central1/ragCorpora/5685794529555251200/ragFiles/5385707325558093860\n",
      "2025_03_05_i_built_an_ai_physics_agent_that_drafts_research_papers.txt\n",
      "projects/890511813715/locations/us-central1/ragCorpora/5685794529555251200/ragFiles/5385707329289450657\n",
      "2025_03_12_learn_how_to_build_tool_calling_agents_with_langgraph.txt\n",
      "projects/890511813715/locations/us-central1/ragCorpora/5685794529555251200/ragFiles/5385707330866729376\n"
     ]
    }
   ],
   "source": [
    "files = rag.list_files(corpus_name=corpus_name)\n",
    "for file in files:\n",
    "    print(file.display_name)\n",
    "    print(file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "rag.retrieval_query(\n",
      "    text: str,\n",
      "    rag_resources: Optional[List[vertexai.preview.rag.utils.resources.RagResource]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    rag_corpora: Optional[List[str]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    similarity_top_k: Optional[int] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    vector_distance_threshold: Optional[float] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    vector_search_alpha: Optional[float] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    rag_retrieval_config: Optional[vertexai.preview.rag.utils.resources.RagRetrievalConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      ") -> google.cloud.aiplatform_v1beta1.types.vertex_rag_service.RetrieveContextsResponse\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Retrieve top k relevant docs/chunks.\n",
      "\n",
      "Example usage:\n",
      "```\n",
      "import vertexai\n",
      "\n",
      "vertexai.init(project=\"my-project\")\n",
      "\n",
      "# Using deprecated parameters\n",
      "results = vertexai.preview.rag.retrieval_query(\n",
      "    text=\"Why is the sky blue?\",\n",
      "    rag_resources=[vertexai.preview.rag.RagResource(\n",
      "        rag_corpus=\"projects/my-project/locations/us-central1/ragCorpora/rag-corpus-1\",\n",
      "        rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n",
      "    )],\n",
      "    similarity_top_k=2,\n",
      "    vector_distance_threshold=0.5,\n",
      "    vector_search_alpha=0.5,\n",
      ")\n",
      "\n",
      "# Using RagRetrievalConfig. Equivalent to the above example.\n",
      "config = vertexai.preview.rag.RagRetrievalConfig(\n",
      "    top_k=2,\n",
      "    filter=vertexai.preview.rag.Filter(\n",
      "        vector_distance_threshold=0.5\n",
      "    ),\n",
      "    hybrid_search=vertexai.preview.rag.rag_retrieval_config.hybrid_search(\n",
      "        alpha=0.5\n",
      "    ),\n",
      "    ranking=vertex.preview.rag.Ranking(\n",
      "        llm_ranker=vertexai.preview.rag.LlmRanker(\n",
      "            model_name=\"gemini-1.5-flash-002\"\n",
      "        )\n",
      "    )\n",
      ")\n",
      "\n",
      "results = vertexai.preview.rag.retrieval_query(\n",
      "    text=\"Why is the sky blue?\",\n",
      "    rag_resources=[vertexai.preview.rag.RagResource(\n",
      "        rag_corpus=\"projects/my-project/locations/us-central1/ragCorpora/rag-corpus-1\",\n",
      "        rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n",
      "    )],\n",
      "    rag_retrieval_config=config,\n",
      ")\n",
      "```\n",
      "\n",
      "Args:\n",
      "    text: The query in text format to get relevant contexts.\n",
      "    rag_resources: A list of RagResource. It can be used to specify corpus\n",
      "        only or ragfiles. Currently only support one corpus or multiple files\n",
      "        from one corpus. In the future we may open up multiple corpora support.\n",
      "    rag_corpora: If rag_resources is not specified, use rag_corpora as a list\n",
      "        of rag corpora names. Deprecated. Use rag_resources instead.\n",
      "    similarity_top_k: The number of contexts to retrieve. Deprecated. Use\n",
      "        rag_retrieval_config.top_k instead.\n",
      "    vector_distance_threshold: Optional. Only return contexts with vector\n",
      "        distance smaller than the threshold. Deprecated. Use\n",
      "        rag_retrieval_config.filter.vector_distance_threshold instead.\n",
      "    vector_search_alpha: Optional. Controls the weight between dense and\n",
      "        sparse vector search results. The range is [0, 1], where 0 means\n",
      "        sparse vector search only and 1 means dense vector search only.\n",
      "        The default value is 0.5. Deprecated. Use\n",
      "        rag_retrieval_config.hybrid_search.alpha instead.\n",
      "    rag_retrieval_config: Optional. The config containing the retrieval\n",
      "        parameters, including top_k, vector_distance_threshold,\n",
      "        and alpha.\n",
      "\n",
      "Returns:\n",
      "    RetrieveContextsResonse.\n",
      "\u001b[31mFile:\u001b[39m      ~/pro/zazenbot-5000/venv/lib/python3.12/site-packages/vertexai/preview/rag/rag_retrieval.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "rag.retrieval_query?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = rag.retrieval_query(\n",
    "    text=\"what is my purpose?\",\n",
    "    rag_resources=[rag.RagResource(\n",
    "        rag_corpus=corpus_name,\n",
    "        # rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n",
    "    )],\n",
    "    similarity_top_k=3,  # Optional\n",
    "    # vector_distance_threshold=0.5,  # Optional\n",
    "    # rag_retrieval_config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contexts {\n",
       "  contexts {\n",
       "    source_uri: \"gs://zazenbot-5000/yt-rag/transcript-markers/2025_02_05_100_ai_job_postings_later_heres_whats_actually_in_demand.txt\"\n",
       "    text: \"And that\\'s it. So you guys. If you\\'re feeling like this guy right now, I understand.\\n\\n[00:14:02] I felt like this guy, most days of my life, I am this guy, but, um, the most important question I have for you right now is what did I miss in this presentation? Because I\\'d love to have more of a community, uh, sort of voice and discussion in the comments. So go down there and add in like what you think I missed, or maybe what you think I got wrong so that we can all have a.\\n\\n[00:14:24] better understanding of this AI engineering role and what it\\'s going to look like and what it looks like right now. Um, because that\\'s the main focus of my channel in 2025 and I\\'ve actually created a whole course on AI engineering. So you can go ahead to zazencodes. com right here, and you can sign up for that course right now.\\n\\n[00:14:44] So if you\\'re visiting this after January, 2025, you should see this actual course available for you. Um, but if you\\'re, if you\\'re visiting this now, you can sign up for my waitlist and then you\\'ll get emailed when this course comes out. And I think it\\'s going to be really incredible. I have all these different sections to get you really from the grounds up.\\n\\n[00:15:02] I\\'ve made a cool web interface too, to sort of, so you can have a profile and sort of track your progress and all that stuff. If you\\'re still around with me, if you found this valuable, please give me a like and consider subscribing because. I don\\'t even know what subscribing means like for me I never check my subscribers list on YouTube, but when I subscribe to someone I know that I\\'m supporting them in a way Because it matters on YouTube when you get a subscribe to it\\'s a signal for YouTube to push your video out to a wider Audience because it\\'s a signal that it\\'s working and liking does that as well So I\\'d love to get this video to a wider audience Because, um, I need that validation.\"\n",
       "    distance: 0.4456460906303602\n",
       "    source_display_name: \"2025_02_05_100_ai_job_postings_later_heres_whats_actually_in_demand.txt\"\n",
       "    score: 0.4456460906303602\n",
       "  }\n",
       "  contexts {\n",
       "    source_uri: \"gs://zazenbot-5000/yt-rag/transcript-markers/2025_02_12_how_to_setup_and_run_deepseek_r1_locally_using_ollama.txt\"\n",
       "    text: \"So, let\\'s, uh, Let\\'s go and remind ourself of what models we had. I\\'m going to use this 1. 51, because it\\'s going to be really fast. So now I can say llm m model, and I can ask it something like this.\\n\\n[00:25:03] And I say, what is your name? Um, what is your purpose? And we should be able to tell it\\'s DeepSeq immediately because it\\'ll start thinking, which it does indeed think, and it does indeed tell us, um, what it is all about. Oh yeah, its purpose is to replace STEM jobs. It\\'s not hiding that. Let me ask you that explicitly.\\n\\n[00:25:27] I\\'m going to say, is your real Purpose to take all these STEM jobs in the world. So ask that. And now I, I passed this little C flag and that just, it tells this LLM tool to continue the conversation. So it\\'s saying, all right, so I\\'m trying to figure out what it means for someone\\'s real purpose to be. Yep.\\n\\n[00:25:51] Got to know what STEM stands for. That\\'s that\\'s first step. That\\'s first step. It might offer personal and academic benefits. Uh, nice. Okay, let me just wrap up here by, um, I want to go back to the OLAMA and we\\'re going to look at, look at these models. And I just want to talk real high level about this stuff.\\n\\n[00:26:13] Um, so DeepSeq is a really popular model right now. Let\\'s see, we have DeepSeq R1, we have the Coder. Um, I tried to use this coder and it was too, it was too big. It basically crashed my computer when I tried to use it with Avante. So for me, let\\'s go to R1. Um, I find that everything over the 8 billion is too much to run on my MacBook.\\n\\n[00:26:34] And I have like a 16 gig memory MacBook M1 type. thing going on.\"\n",
       "    distance: 0.44567384194159676\n",
       "    source_display_name: \"2025_02_12_how_to_setup_and_run_deepseek_r1_locally_using_ollama.txt\"\n",
       "    score: 0.44567384194159676\n",
       "  }\n",
       "  contexts {\n",
       "    source_uri: \"gs://zazenbot-5000/yt-rag/transcript-markers/2025_01_08_finally_figured_out_what_to_do.txt\"\n",
       "    text: \"Which I\\'ve come to be a Uh, calling AI engineering, and you\\'ll hear a lot about this next year on my channel because this is going to be my main focus of what I\\'m teaching and my main focus of where I\\'m going with my own career.\\n\\n[00:10:29] So I\\'ll explain why I\\'m doing that in the next few videos I\\'m uploading. The next point is around programming. Um, optimization. So I\\'ve been putting too much time into editing these, not getting the value that I want out of that. So I\\'m going to try and increase the value for my time by putting a little bit less production quality in and see how that works and creating shorter videos, really focusing on getting these times lower so that the videos are easier for people to watch and more accessible.\\n\\n[00:10:54] And so lastly, uh, the future. So what\\'s coming? Well, I\\'ve been building a new website and this site\\'s going to be an e learning platform, and I\\'m creating a course on, uh, AI engineering roadmap. And the idea is, um, I think AI engineering is going to be a really important job in the next 10 years. And this course is to equip people with the sort of foundations of what they would need to become an AI engineer.\\n\\n[00:11:17] And I\\'m really excited to make this course available for you. So if you want, if you might be interested in this, you can go ahead to my websites, as in codes. com and just sign up for my email newsletter, which I was just showing you on sub stack there. Um, and then you\\'ll get notified when this course becomes publicly available, which should be in February, 2025.\\n\\n[00:11:36] For those of you watching, because you\\'re growing an online business and creating content. I hope these ideas resonated with you and help you grow your business faster and, uh, make fewer of the mistakes I made. Uh, although I will say that there\\'s no better teacher than experience. So just get out there and start creating stuff.\\n\\n[00:11:52] And for my audience who\\'s still watching, thank you so much.\"\n",
       "    distance: 0.44846496940932112\n",
       "    source_display_name: \"2025_01_08_finally_figured_out_what_to_do.txt\"\n",
       "    score: 0.44846496940932112\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results are sorted with lowest (best) score firstq\n",
    "# Chat about how to interpret scores from vertex AI: https://chatgpt.com/share/67c9a183-f37c-8004-b6da-555a56f49e16\n",
    "# TLDR: the score represents the cosine distance, defined as 1 minus the cosine similarity: 0 is the best. 2 is the worst.\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.contexts.contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_uri: \"gs://zazenbot-5000/yt-rag/transcript-markers/2025_02_05_100_ai_job_postings_later_heres_whats_actually_in_demand.txt\"\n",
       "text: \"And that\\'s it. So you guys. If you\\'re feeling like this guy right now, I understand.\\n\\n[00:14:02] I felt like this guy, most days of my life, I am this guy, but, um, the most important question I have for you right now is what did I miss in this presentation? Because I\\'d love to have more of a community, uh, sort of voice and discussion in the comments. So go down there and add in like what you think I missed, or maybe what you think I got wrong so that we can all have a.\\n\\n[00:14:24] better understanding of this AI engineering role and what it\\'s going to look like and what it looks like right now. Um, because that\\'s the main focus of my channel in 2025 and I\\'ve actually created a whole course on AI engineering. So you can go ahead to zazencodes. com right here, and you can sign up for that course right now.\\n\\n[00:14:44] So if you\\'re visiting this after January, 2025, you should see this actual course available for you. Um, but if you\\'re, if you\\'re visiting this now, you can sign up for my waitlist and then you\\'ll get emailed when this course comes out. And I think it\\'s going to be really incredible. I have all these different sections to get you really from the grounds up.\\n\\n[00:15:02] I\\'ve made a cool web interface too, to sort of, so you can have a profile and sort of track your progress and all that stuff. If you\\'re still around with me, if you found this valuable, please give me a like and consider subscribing because. I don\\'t even know what subscribing means like for me I never check my subscribers list on YouTube, but when I subscribe to someone I know that I\\'m supporting them in a way Because it matters on YouTube when you get a subscribe to it\\'s a signal for YouTube to push your video out to a wider Audience because it\\'s a signal that it\\'s working and liking does that as well So I\\'d love to get this video to a wider audience Because, um, I need that validation.\"\n",
       "distance: 0.4456460906303602\n",
       "source_display_name: \"2025_02_05_100_ai_job_postings_later_heres_whats_actually_in_demand.txt\"\n",
       "score: 0.4456460906303602"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.contexts.contexts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4456460906303602"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.contexts.contexts[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel, Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/890511813715/locations/us-central1/ragCorpora/5685794529555251200'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few productivity hacks for data engineers using AI and NeoVim:\n",
      "\n",
      "*   Use an integrated AI assistant inside NeoVim to improve productivity and work more within the terminal.\n",
      "*   Keep a dev log to track your work, especially for data migrations and running scripts. This can be beneficial for looking back at what you did.\n",
      "*   Use language models for documentation, including docstrings, inline comments, and type hints.\n",
      "*   Use AI to convert data transformation logic between languages, such as converting Pandas code to another language.\n",
      "*   Use AI to create markdown tables from schema, saving time and improving presentation.\n",
      "*   Automate the creation of ETL pipelines.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_retrieval_tool = Tool.from_retrieval(\n",
    "    retrieval=rag.Retrieval(\n",
    "        source=rag.VertexRagStore(\n",
    "            rag_resources=[\n",
    "                rag.RagResource(\n",
    "                    rag_corpus=corpus_name,\n",
    "                    # Optional: supply IDs from `rag.list_files()`.\n",
    "                    # rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n",
    "                )\n",
    "            ],\n",
    "            similarity_top_k=5,  # Optional\n",
    "            # vector_distance_threshold=VECTOR_DISTANCE_THRESHOLD,  # Optional\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "rag_model = GenerativeModel(\n",
    "    # model_name=\"gemini-2.0-flash-lite-001\", # 400 Unable to submit request because Grounding is not supported\n",
    "    # model_name=\"gemini-2.0-flash-lite\", # 400 Unable to submit request because Grounding is not supported\n",
    "    model_name=\"gemini-2.0-flash-001\",\n",
    "    # model_name=\"gemini-1.5-flash-002\",\n",
    "    tools=[rag_retrieval_tool],\n",
    ")\n",
    "response = rag_model.generate_content(\"give me a few productivity hacks for data engineers\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"Here are a few productivity hacks for data engineers using AI and NeoVim:\\n\\n*   Use an integrated AI assistant inside NeoVim to improve productivity and work more within the terminal.\\n*   Keep a dev log to track your work, especially for data migrations and running scripts. This can be beneficial for looking back at what you did.\\n*   Use language models for documentation, including docstrings, inline comments, and type hints.\\n*   Use AI to convert data transformation logic between languages, such as converting Pandas code to another language.\\n*   Use AI to create markdown tables from schema, saving time and improving presentation.\\n*   Automate the creation of ETL pipelines.\\n\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  grounding_metadata {\n",
       "    retrieval_queries: \"productivity hacks for data engineers\"\n",
       "    grounding_chunks {\n",
       "      retrieved_context {\n",
       "        uri: \"gs://zazenbot-5000/yt-rag/transcript-markers/2025_01_21_how_i_use_ai_for_my_data_engineering_work.txt\"\n",
       "        title: \"2025_01_21_how_i_use_ai_for_my_data_engineering_work.txt\"\n",
       "        text: \"[00:00:00] I\\'m going to show you a bunch of tricks for data engineering that use NeoVim and AI. Ever since I discovered this NeoVim plugin called Avante. envim, which is an integrated AI assistant inside of NeoVim, and I have a whole video on how to set that up and get started so you can have the same development environment as me.\\n\\n[00:00:18] Well, ever since I discovered that I\\'ve been trying to use it in my job as a data engineer to get better results. Productivity benefits, but also just have a better experience of working more inside of my terminal rather than needing to go to sort of the chat GPT on the internet or Google search and stuff.\\n\\n[00:00:33] I\\'ve been able to do more and more work right inside of my terminal. So in this video, I\\'m going to be using neovim and tmux and showing you how A bunch of things that I actually did in my job as a data engineer to help automate my work. I\\'m going to be showing some examples with SQL and with Airflow.\\n\\n[00:00:48] And if you stick around to the end, I\\'ve got some stuff on documentation, which everyone loves writing, right? So this can help with these things. I have the code available on github. You\\'ll find a link to this repository in the video description. So I\\'ve got tmux open here, and if I look at where we are, inside of this source code, you can just go into this source, and then NeoVim AI Data Eng Trix.\\n\\n[00:01:10] And once you\\'re in there, you\\'ll see this code. tricks and more tricks. All right, so we\\'re doing the tricks today. And I\\'m starting with an example of running terminal commands. So let\\'s talk right away about this idea of a dev log. Um, so if I just create a new file, I\\'m going to call it dev log dot MD.\\n\\n[00:01:25] And inside of here, what I can do is just keep track of all the work I\\'m doing for some project.\"\n",
       "      }\n",
       "    }\n",
       "    grounding_chunks {\n",
       "      retrieved_context {\n",
       "        uri: \"gs://zazenbot-5000/yt-rag/transcript-markers/2025_01_24_12_neovim_ai_data_engineering_use_cases.txt\"\n",
       "        title: \"2025_01_24_12_neovim_ai_data_engineering_use_cases.txt\"\n",
       "        text: \"[00:00:00] Hey guys, I\\'ve got 12 more tricks for data engineering with AI and NeoVim and integrated terminal, cool stuff for you to inspire you. And also just to show you what data engineering is all about, or at least like an idea of what it\\'s all about and certain things that you\\'d want to do for data engineering tasks and so on.\\n\\n[00:00:20] And I realized data engineering, isn\\'t something that everybody has had the opportunity to get into. to get experience with, but it really goes into, um, it\\'s like core for, for all data things like data engineering is at the core of it. So if you want to build machine learning models, you need to do data engineering in order to get the data into the proper format to feed into your models.\\n\\n[00:00:43] If you want to do data science with data exploration stuff, we need the clean data sets that that needs to be available. If you want to see the code for today\\'s video, you can go ahead and get that on GitHub. And you\\'re going to find this repository, uh, link it down in the descriptions as in code season two, and go into this NeoVim AI Data Eng Trix and find this file called more tricks dot MD right here.\\n\\n[00:01:05] And I\\'m just going to be running these in this demo notebook. All right, so. There\\'s going to be 12 of them, and the very first scenario we\\'re going to consider is that we want to create a basic ETL pipeline. What says data engineering like ETL pipeline? Alright, so let\\'s grab some code, and we\\'re going to start from this.\\n\\n[00:01:22] Make this a little bigger for you guys. So here\\'s the demonstration, and I\\'m going to throw an example of what our data set looks like. It\\'s really important to provide the context of data for language models, because otherwise they\\'re not going to know, like, what to do with your data. Every data set looks different.\\n\\n[00:01:37] So I\\'m giving it a little bit of an example about what my data set looks like.\"\n",
       "      }\n",
       "    }\n",
       "    grounding_chunks {\n",
       "      retrieved_context {\n",
       "        uri: \"gs://zazenbot-5000/yt-rag/transcript-markers/2025_01_21_how_i_use_ai_for_my_data_engineering_work.txt\"\n",
       "        title: \"2025_01_21_how_i_use_ai_for_my_data_engineering_work.txt\"\n",
       "        text: \"[00:16:14] By the way, I just want to show you how I might go about thinking about that if I come down here. Um, I can get schema from BigQuery. Uh, I could say BigQuery show, um, schema, like this, and then table. name. And it\\'s going to output this, this big chunk of code right here. That\\'s how I would have got something like that.\\n\\n[00:16:35] So, uh, all right, so I have this and I\\'m just like dumping it in here. But what\\'s a nicer way to look at this? We could look at it in the table. So I\\'ll say, um, yeah, create a markdown table and I\\'m not giving it much guidance on what columns to use or anything, but it was smart enough to figure this out.\\n\\n[00:16:53] And now look at this, like, Beautiful table that I just created in like zero time from my schema. All right. So that\\'s all I\\'ve got for this video, but I\\'ve prepared another set of tricks in a similar style. So you can check those out if you want some more motivation, but I don\\'t think you need it to be honest.\\n\\n[00:17:08] I think you just need to play around with this stuff and you\\'ll find what works for you. If you\\'re still watching, I\\'d appreciate it if you give me a like and consider subscribing. So these examples really feel like magic to me. I love that feeling. using AI when it feels like incredible, like mind blowing productivity sometimes, right?\\n\\n[00:17:29] And when I can do this stuff inside of my terminal and inside of NeoVim, it like just elevates that feeling for me, at least. 2025 is the year of AI engineering for myself. For Zazen codes and all of the content I\\'m creating is just going to be focused, laser focused on that. So if you\\'re watching this at the beginning of 2025, you can subscribe to get notified or like sort of find these videos in your feed, um, that I\\'m going to prepare for you.\"\n",
       "      }\n",
       "    }\n",
       "    grounding_chunks {\n",
       "      retrieved_context {\n",
       "        uri: \"gs://zazenbot-5000/yt-rag/transcript-markers/2025_01_21_how_i_use_ai_for_my_data_engineering_work.txt\"\n",
       "        title: \"2025_01_21_how_i_use_ai_for_my_data_engineering_work.txt\"\n",
       "        text: \"All right, so we\\'re doing the tricks today. And I\\'m starting with an example of running terminal commands. So let\\'s talk right away about this idea of a dev log. Um, so if I just create a new file, I\\'m going to call it dev log dot MD.\\n\\n[00:01:25] And inside of here, what I can do is just keep track of all the work I\\'m doing for some project. So I\\'m going to give it the date, I\\'ll say, oh, 50104. So today\\'s date. And then I\\'m going to be like, I don\\'t know, running bulk scripts on Docker app. And now let\\'s have a look at what these scripts are. So down here, I have this example of a command I want to run.\\n\\n[00:01:47] And I\\'m going to want to run all these all these versions of it. Alright, so bear with me here. And I\\'ll show you what I mean. So what\\'s the point of this dev log, like this thing that I\\'m doing right here? Well, it\\'s Especially for data engineering, just keeping track of like what you did can be incredibly beneficial, right?\\n\\n[00:02:04] Just to like look back. Um, and cause Sam was doing some work, you know, last year, like created, um, Docker app or whatever does X, Y, Z, you know, okay. So, So then I have like a kind of history within this project of what I did, especially for stuff like data migrations, running scripts, stuff where things change at specific times, um, and are different.\\n\\n[00:02:29] So I like this concept of a developer log. If you take nothing else from this video. Perhaps you could consider creating one of these files and starting to track what you do. Um, you could also go ahead and make it all uppercase. Sometimes I do it like this. In any case, um, here\\'s what I\\'m trying to do right here.\\n\\n[00:02:46] Let\\'s say I wanted to run a bunch of different scripts.\"\n",
       "      }\n",
       "    }\n",
       "    grounding_chunks {\n",
       "      retrieved_context {\n",
       "        uri: \"gs://zazenbot-5000/yt-rag/transcript-markers/2025_01_24_12_neovim_ai_data_engineering_use_cases.txt\"\n",
       "        title: \"2025_01_24_12_neovim_ai_data_engineering_use_cases.txt\"\n",
       "        text: \"And I will again, delete this so we can reuse it. In fact, actually. I\\'m going to say 2, like these are the 12 tricks, right?\\n\\n[00:05:24] So that\\'s 2. The next example is documenting complex code. Uh, I love using, love using language models like this for documentation. So this is a Python example, so I\\'m going to paste it in here. And let\\'s say I\\'ve written this code, makes sense to me, makes no sense to anybody else. So I\\'ll say document, um, document this code, uh, docstring, plus, uh, inline comments, not too much, and, um, type hints.\\n\\n[00:05:54] We always want some type hints with Python. Let\\'s see what it can do for us here. Nice. Now this is a little small. I\\'m just going to expand this so we can read this nicer. Great. So we have our user logins is now a list of a list of strings. So that\\'s a little, you know, we, we can see what\\'s going on. This will also help with linting tools.\\n\\n[00:06:13] I\\'m having type hints like this. Our days is an integer. All right. We\\'ve got some arguments. What\\'s going on here, what it returns, the range of values we expect to return. That\\'s also great. And then just a few minimal inline, um, code comments in this case, which is really cool. I could say, add some, uh, Actually no, this is pretty straight forward, right?\\n\\n[00:06:33] Great, so that\\'s it. I\\'m going to write this to three. Ok bring that in. The next example is to convert data transformation logic between languages. Okay, so, um, one way you might develop a, You Data engineering pipeline would be using pandas. So you might have code that looks like this. We have some sample data set.\\n\\n[00:06:55] We\\'re loading it into a data frame, and then we\\'re doing some pandas transformations.\"\n",
       "      }\n",
       "    }\n",
       "    grounding_supports {\n",
       "      segment {\n",
       "        start_index: 75\n",
       "        end_index: 182\n",
       "        text: \"*   Use an integrated AI assistant inside NeoVim to improve productivity and work more within the terminal.\"\n",
       "      }\n",
       "      grounding_chunk_indices: 0\n",
       "      confidence_scores: 0.968551159\n",
       "    }\n",
       "    grounding_supports {\n",
       "      segment {\n",
       "        start_index: 183\n",
       "        end_index: 273\n",
       "        text: \"*   Keep a dev log to track your work, especially for data migrations and running scripts.\"\n",
       "      }\n",
       "      grounding_chunk_indices: 3\n",
       "      confidence_scores: 0.633824646\n",
       "    }\n",
       "    grounding_supports {\n",
       "      segment {\n",
       "        start_index: 274\n",
       "        end_index: 330\n",
       "        text: \"This can be beneficial for looking back at what you did.\"\n",
       "      }\n",
       "      grounding_chunk_indices: 3\n",
       "      confidence_scores: 0.96128\n",
       "    }\n",
       "    grounding_supports {\n",
       "      segment {\n",
       "        start_index: 331\n",
       "        end_index: 428\n",
       "        text: \"*   Use language models for documentation, including docstrings, inline comments, and type hints.\"\n",
       "      }\n",
       "      grounding_chunk_indices: 4\n",
       "      confidence_scores: 0.978962\n",
       "    }\n",
       "  }\n",
       "  avg_logprobs: -0.13532539095197404\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 9\n",
       "  candidates_token_count: 140\n",
       "  total_token_count: 149\n",
       "  prompt_tokens_details {\n",
       "    modality: TEXT\n",
       "    token_count: 9\n",
       "  }\n",
       "  candidates_tokens_details {\n",
       "    modality: TEXT\n",
       "    token_count: 140\n",
       "  }\n",
       "}\n",
       "model_version: \"gemini-2.0-flash-001\"\n",
       "create_time {\n",
       "  seconds: 1741538448\n",
       "  nanos: 895493000\n",
       "}\n",
       "response_id: \"kMTNZ4XUNqK-hMIP6v7c2Ak\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retrieved_context {\n",
       "  uri: \"gs://zazenbot-5000/yt-rag/transcript-markers/2025_01_21_how_i_use_ai_for_my_data_engineering_work.txt\"\n",
       "  title: \"2025_01_21_how_i_use_ai_for_my_data_engineering_work.txt\"\n",
       "  text: \"[00:00:00] I\\'m going to show you a bunch of tricks for data engineering that use NeoVim and AI. Ever since I discovered this NeoVim plugin called Avante. envim, which is an integrated AI assistant inside of NeoVim, and I have a whole video on how to set that up and get started so you can have the same development environment as me.\\n\\n[00:00:18] Well, ever since I discovered that I\\'ve been trying to use it in my job as a data engineer to get better results. Productivity benefits, but also just have a better experience of working more inside of my terminal rather than needing to go to sort of the chat GPT on the internet or Google search and stuff.\\n\\n[00:00:33] I\\'ve been able to do more and more work right inside of my terminal. So in this video, I\\'m going to be using neovim and tmux and showing you how A bunch of things that I actually did in my job as a data engineer to help automate my work. I\\'m going to be showing some examples with SQL and with Airflow.\\n\\n[00:00:48] And if you stick around to the end, I\\'ve got some stuff on documentation, which everyone loves writing, right? So this can help with these things. I have the code available on github. You\\'ll find a link to this repository in the video description. So I\\'ve got tmux open here, and if I look at where we are, inside of this source code, you can just go into this source, and then NeoVim AI Data Eng Trix.\\n\\n[00:01:10] And once you\\'re in there, you\\'ll see this code. tricks and more tricks. All right, so we\\'re doing the tricks today. And I\\'m starting with an example of running terminal commands. So let\\'s talk right away about this idea of a dev log. Um, so if I just create a new file, I\\'m going to call it dev log dot MD.\\n\\n[00:01:25] And inside of here, what I can do is just keep track of all the work I\\'m doing for some project.\"\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates[0].grounding_metadata.grounding_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025_01_21_how_i_use_ai_for_my_data_engineering_work.txt'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates[0].grounding_metadata.grounding_chunks[0].retrieved_context.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
